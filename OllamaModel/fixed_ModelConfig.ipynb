{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOkkL3chIRcAz8KduEIjGZL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Niroshan2812/LocalJanitorAgent/blob/main/OllamaModel/fixed_ModelConfig.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#mount Google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tnwZGj2rQJnr",
        "outputId": "030da244-5f5f-44db-afb4-e66f4274f654"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Create Ollama Folder\n",
        "!mkdir -p \"/content/drive/MyDrive/ollama\"\n",
        "!mkdir -p \"/content/drive/MyDrive/ollama/models\"\n"
      ],
      "metadata": {
        "id": "xXYOGM7IQPnm"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Download ollama binary\n",
        "import os\n",
        "\n",
        "ollama_dir = \"/content/drive/MyDrive/ollama\"\n",
        "ollama_bin = f\"{ollama_dir}/bin/ollama\"\n",
        "\n",
        "if not os.path.exists(ollama_bin):\n",
        "    print(\"Downloading and installing Ollama…\")\n",
        "    %cd $ollama_dir\n",
        "    !wget https://ollama.com/download/ollama-linux-amd64.tgz -O ollama.tgz\n",
        "    !tar -xvzf ollama.tgz\n",
        "else:\n",
        "    print(\"Ollama already installed.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZWreGMu1QVcW",
        "outputId": "31fe0463-0499-4821-cbf6-0d7b4cef0af5"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ollama already installed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# IMPORTANT: Restore executable permission after every runtime reset\n",
        "!chmod +x /content/drive/MyDrive/ollama/bin/ollama"
      ],
      "metadata": {
        "id": "QBTlNyzHV8-Q"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tell Ollama to use models from Drive\n",
        "import os\n",
        "\n",
        "os.environ[\"OLLAMA_MODELS\"] = \"/content/drive/MyDrive/ollama/models\"\n",
        "print(\"OLLAMA_MODELS set to persistent folder.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N5Q49sBaQYEJ",
        "outputId": "9ccc1135-2c1d-4abd-b689-cba011b28561"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OLLAMA_MODELS set to persistent folder.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Start Ollama server in Real Back\n",
        "# Absolute path\n",
        "ollama_bin = \"/content/drive/MyDrive/ollama/bin/ollama\"\n",
        "\n",
        "# Start server in detached mode\n",
        "!nohup $ollama_bin serve > /dev/null 2>&1 &\n",
        "\n",
        "import time\n",
        "time.sleep(3)\n",
        "\n",
        "print(\"Ollama server started in background \")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E5sXml2KRwfo",
        "outputId": "4396b3f5-4064-48f0-fc24-95f6b009accf"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ollama server started in background \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pull model\n",
        "!$ollama_bin pull qwen2.5-coder\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0JfM3fJ4R0cu",
        "outputId": "44e8b963-8ebd-486a-9a26-acfeeeee794f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install ngrok\n",
        "!wget https://bin.equinox.io/c/bNyj1mQVY4c/ngrok-v3-stable-linux-amd64.tgz -O ngrok.tgz\n",
        "!tar -xvzf ngrok.tgz\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GT4NWwnvSie3",
        "outputId": "33c87c19-ae87-4551-f110-48854a7a382c"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-11-21 07:39:30--  https://bin.equinox.io/c/bNyj1mQVY4c/ngrok-v3-stable-linux-amd64.tgz\n",
            "Resolving bin.equinox.io (bin.equinox.io)... 13.248.244.96, 99.83.220.108, 75.2.60.68, ...\n",
            "Connecting to bin.equinox.io (bin.equinox.io)|13.248.244.96|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 9322357 (8.9M) [application/octet-stream]\n",
            "Saving to: ‘ngrok.tgz’\n",
            "\n",
            "ngrok.tgz           100%[===================>]   8.89M  11.6MB/s    in 0.8s    \n",
            "\n",
            "2025-11-21 07:39:32 (11.6 MB/s) - ‘ngrok.tgz’ saved [9322357/9322357]\n",
            "\n",
            "ngrok\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load ngrok with auth\n",
        "from google.colab import userdata\n",
        "auth = userdata.get('NGROK_authToken')\n",
        "\n",
        "!./ngrok authtoken $auth\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K6AzFeWjSnHV",
        "outputId": "d025bdbb-0b2c-4a6e-9b2c-4d0da620f4fb"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Start turnnel\n",
        "!./ngrok http 11434 --host-header=\"localhost:11434\" --log=stdout\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UjudkJQCSrzN",
        "outputId": "c6f66381-20a6-428e-8db1-92573f51e7fb"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32mINFO\u001b[0m[11-21|07:39:46] no configuration paths supplied \n",
            "\u001b[32mINFO\u001b[0m[11-21|07:39:46] using configuration at default config path \u001b[32mpath\u001b[0m=/root/.config/ngrok/ngrok.yml\n",
            "\u001b[32mINFO\u001b[0m[11-21|07:39:46] open config file                         \u001b[32mpath\u001b[0m=/root/.config/ngrok/ngrok.yml \u001b[32merr\u001b[0m=nil\n",
            "t=2025-11-21T07:39:46+0000 lvl=info msg=\"FIPS 140 mode\" enabled=false\n",
            "t=2025-11-21T07:39:46+0000 lvl=info msg=\"starting web service\" obj=web addr=127.0.0.1:4040 allow_hosts=[]\n",
            "t=2025-11-21T07:39:46+0000 lvl=info msg=\"client session established\" obj=tunnels.session\n",
            "t=2025-11-21T07:39:46+0000 lvl=info msg=\"tunnel session started\" obj=tunnels.session\n",
            "t=2025-11-21T07:39:47+0000 lvl=info msg=\"started tunnel\" obj=tunnels name=command_line addr=http://localhost:11434 url=https://milanaise-unpathological-earlene.ngrok-free.dev\n",
            "t=2025-11-21T07:39:59+0000 lvl=info msg=\"join connections\" obj=join id=122d826cc377 l=127.0.0.1:11434 r=61.245.171.37:57034\n",
            "t=2025-11-21T07:48:19+0000 lvl=info msg=\"join connections\" obj=join id=00a97a0fa46a l=127.0.0.1:11434 r=61.245.171.37:63984\n",
            "t=2025-11-21T07:51:09+0000 lvl=info msg=\"join connections\" obj=join id=41e1358574e2 l=127.0.0.1:11434 r=61.245.171.37:34187\n",
            "t=2025-11-21T07:52:50+0000 lvl=info msg=\"join connections\" obj=join id=35d34d840b05 l=127.0.0.1:11434 r=61.245.171.37:57037\n",
            "t=2025-11-21T07:53:26+0000 lvl=info msg=\"received stop request\" obj=app stopReq=\"{err:<nil> restart:false}\"\n",
            "t=2025-11-21T07:53:26+0000 lvl=info msg=\"session closing\" obj=tunnels.session err=nil\n",
            "t=2025-11-21T07:53:26+0000 lvl=info msg=\"accept failed\" obj=tunnels.session obj=csess id=7971b29b7f9e err=\"reconnecting session closed\"\n",
            "t=2025-11-21T07:53:26+0000 lvl=info msg=\"failed to accept connection: Listener closed\" obj=tunnels.session clientid=d2fbbfb553f562608853044fc1ac2cf8\n",
            "t=2025-11-21T07:53:26+0000 lvl=warn msg=\"Stopping forwarder\" name=command_line acceptErr=\"failed to accept connection: Listener closed\"\n",
            "t=2025-11-21T07:53:26+0000 lvl=warn msg=\"Error restarting forwarder\" name=command_line err=\"failed to start tunnel: session closed\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -l /content/drive/MyDrive/ollama/bin\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "woB13x3cWIbu",
        "outputId": "ce5a37be-a968-485f-ad9b-f0061a47e402"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ls: cannot access '/content/drive/MyDrive/ollama/bin': No such file or directory\n"
          ]
        }
      ]
    }
  ]
}